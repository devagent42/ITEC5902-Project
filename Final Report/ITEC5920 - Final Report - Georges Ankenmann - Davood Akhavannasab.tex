\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{lscape}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Time Series Classification \\ ITEC5920 Final Project Report}

\author{\IEEEauthorblockN{Georges Ankenmann}
\IEEEauthorblockA{\textit{School of Information Technology} \\
\textit{Carleton University}\\
Ottawa, Canada \\
GeorgesAnkenmann@cmail.carleton.ca}
\and
\IEEEauthorblockN{Davood Akhavannasab}
\IEEEauthorblockA{\textit{School of Information Technology} \\
\textit{Carleton University}\\
Ottawa, Canada \\
DavoodAkhavannasab@cmail.carleton.ca}

}

\maketitle

\begin{abstract}
In this project we are tasked to come up with various deep learning models that are to be trained on a provided dataset. This paper talks about our approach, our chosen models, and the results of training the models on the data.
\end{abstract}

\begin{IEEEkeywords}
deep learning, machine learning, time, series, classification, neural network, cnn, lstm, mlp, vgg, convolutional neural network, multilayer perceptron, long short-term memory, very deep convolutional networks, n-beats
\end{IEEEkeywords}

\section{Introduction}
Nowadays, sensors can be seen in many devices such as smartphones, automobiles, and industrial instruments. Also, sensor information plays a critical role in a wide range of industries from health to safety. This information usually comes in a time-series format can be helpful in different fields such as disaster prevention, human health alerts, and air quality control by measurement interpretation. Some sensor information may contain noise (usually environmentally). We can find patterns by classifying the sensor information. The most common challenging issues of classification application are when we face imbalanced data and lack of training data. For example, if you consider a time series data set containing vibration data of a bridge, we will face a lack of earthquake information while it is a rare phenomenon. In several related works, CNN (Convolutional Neural Network), Multilayer Perceptrons (MLP), and LSTM (Long Short Term Memory network) have succeeded in time-series classification problems.
\section{Research and Literature Review}
This section contains literature for deep learning for time series classification. 

The authors of article \cite{b8} have proposed a model for sensor classificatoin by encoding time series data into colored images (two-dimentional). Then they did image concatenation to image feature identity and then did image classification by Convolutional Neural Network (CNN). Angular Difference Field (GADF), Gramian Angular Summation Field (GASF),  and Markov Transition Field (MTF) has been utilized for time series data transformation into images. In fact they have used these functions to prepare multivariate sensor data to obtain two-dimensional images. They have proved that their proposed model improved the classification results in comparison with other deep learning classification methods. They have used ECG and Wafer datasets in order to evaluate their model. 
\par In another work (\cite{ramakrishnan2018network}),  an outstanding model for network trafic classification has been proposed. Their work contains three tasks for predicting future network volume traffic, future packet protocol and future packet distribution through Recurrent Neural Network(RNN), Long Short Term Memory(LSTM) and Gated Recurrent Units(GRU). In the second task(future packet protocol prediction), they have focused on layer seven protocols such as SNMP, and HTTPS. As a matter of fact, they have considered some network packet features such as packet legnth, packet header information, and statistical information such as source IP and destination port as input and have considered packet protocol as output. They have evaluated their proposed models by GEANT and Abilene public datasets. Also, they have collected real networking data from network nodes by themselves. The results show that RNN and LSTM had amazing improvements in network traffic prediction in comparison with other proposed models such as Autoregressive Integrated Moving Average (ARIMA).  

\par The authors of one work (\cite{shen2021accurate}) have defined a DApp fingerprinting technique utilizing Graph Neural Networks (GNN) to identify different DApps by observing the user traffic stream. Their proposal consists of an information graph structure named Traffic Interaction Graph (TIG). TIG represents each traffic flow, comprising of packets resulting from client-server communications.  The main advantage of TIG is that it shows much data like the original stream, such as packet length, packet direction, and packet order. They proposed a GNN-base classifier that extracts input TIG's features to recognize graph structures.

\par Several works have focused on online shopping prediction by deep learning. In one article(\cite{hidasi2015session}) RNN has been used on recommender systems, while these systems have one common issue to make decisions based on short session-based Information and usually do not track the session information based on customer user IDs. They have utilized two datasets. The first one belongs to RecSys Challenge 2015, and the second one has been collected from an online service platform. They have eliminated 1-click sessions and combined the buyer's and clickers' Information to prepare the dataset.  They have tried to focus on classifying user intent to make a purchase. Their results show that their work has remarkably improvemened recommender systems by applying RNNs. The authors of \cite{lang2017understanding} have utilized RNN for customer behaviour prediction using clickstream information and the have proved RNN has better results than Logistic Regression. Also, they have admitted that the only disadvantage of RNNs is longer training time, but they mentioned the point that in RNNs, we do not need much feature engineering. The authors of other related work (\cite{toth2017predicting}) have utilized LSTM RNNs(emphasizing single RNNs architectures) for shopping behaviour prediction using clickstream information.  

\par Several researchers such as \cite{croda2019sales} and \cite{elmasdotter2018comparative} have utilized Neural Networks to optimize inventory management systems through sales prediction. Suppose companies know about the number of their future sales. In that case, they can optimize their inventory management system. In first paper (\cite{croda2019sales}) MPNN(Multilayer Perceptron Neural Network) has been implemented to predict future sales to anticipate the required space of the company warehouse in the future. They have used sales information of a company for one year to predict future sales and see how many warehouses should be constructed in the future. They have admitted that MPNN does not work precisely in large time-series datasets for behaviour prediction. However, still, MPNN outperforms traditional machine learning methods in small datasets for non-linear behaviour prediction. The have utilized RMSE in model evaluation. In second work (\cite{elmasdotter2018comparative}) LSTM and ARIMA have been utilized to predict grocery sales and then optimize the inventory system to reduce the number of waste foods. They have trained the models through sales information of a chain grocery company from 2013 to 2017. They have proved that LSTM has better results in comparison with ARIMA in predicting the coming seven days of given data. RMSE and MAE have been used for model evaluation. 

\section{Methodology}
We are given a dataset that contains a matrix of 336 measurements with each measurement contains 3000 data samples. With this data, we must train a deep learning model that will allow for automatic classification of new data. Data is already standardised, so we do not need to reduce it further. We will then proceed with training and comparing various models, notably Multilayer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and a hybrid of models. We want to have multiple models to choose from as one model might be able to more accurately classify new sensor data over another given the available dataset. Once we have a trained model, we will want to validate the model by feeding it existing data to confirm the expected results, making adjustments accordingly. Once we have confirmed that the models are trained correctly, we will be feeding it new data and provide results.
\section{Results}
See table \ref{tab:data-wo-aug} for the results of the data without augmentation. See table \ref{tab:data-w-tsaug-aug} for the results of the data with augmentation.
\section{Discussion}
\subsection{Source Code}
All the source code for this project is included in the submission and it is also available on the project's GitHub repository \cite{github}.
\subsection{Data}
The data was provided to us for this project. It consisted of sensor measurements from 336 sensors, with 3000 measurements for each sensor. We initially identified that the data was unbalanced and proceeded to fix this with random over sampling. The Keras Python libraries \cite{keras} were used for most of the project. Tensorflow and other libraries were used to augment the Keras libraries. Early stoppage was implemented for all models with idendical stoppage properties to allow for consistent training. The Root Mean Square Error (RMSE) values were monitored and training was stopped if after 15 epochs there was no significant decrease in the RMSE values. According to our research, a "better" model has a lower RMSE value. Table \ref{tab:data-wo-aug} and table \ref{tab:data-w-tsaug-aug} contains the min, max, average, and mean, of the tracked metrics. This data in this table will be discussed shortly in the next sections. A Graphical Processor Unit (GPU) was used as much as possible to speed up the training of the various models.
\subsection{Data Augmentation and Unbalanced Data}
Upon feedback from the presentation from the Professor and other students, we proceeded to augment the data using an open source Python library called Tsaug \cite{b3} and used the SMOTEENN algorithm \cite{b4} to fix the unbalanced data and the data augmentation issues noted during the presentation. The SMOTEENN algorithm uses a combination of over sampling and under sampling techniques. It uses the Synthetic Minority Over-sampling Technique (SMOTE) \cite{b5} for over sampling, and Edited Nearest Neighbours (ENN) for under sampling \cite{b6}. After using the two techniques to fix the unbalanced data and using the Tsaug library for data augmentation, we proceeded to train the models on the provided dataset.
\subsection{CNN Model}
The first model we designed was a Convolutional Neural Network (CNN) based model. Upon playing around with the parameters and mixing and matching layers, we found that a 12 layer model with 10 hidden layers offered the best results for our dataset. The hidden layers consisted of alternating Keras Conv1D layers and Keras MaxPooling1D layers with decreasing units. The output layer is a single Keras Dense layer with one single unit.
\subsection{MLP Model}
The second model we designed was a Multilayer Perceptron (MLP) based model. Upon playing around with the parameters and mixing and matching layers, we found that a 12 layer model with 10 hidden layers offered decent performance. All of the layers consisted of the Keras Dense layers with a decreasing amount of units ("neurons") for each layer. The output layer is a single Keras Dense layer with one single unit. 
\subsection{LTSM Model}
The third model we designed was a Long short-term memory (LSTM) based network. LSTM is a type of a Recurrent Neural Network (RNN). Similar to the previous models, we found that a 12 layer model with 10 hidden layers offers decent performance. The hidden layers consisted of one Keras LSTM layer with 50 units which then feed into 10 Keras Dense layers with 32 units each. The output layer is a single Keras Dense layer with one single unit.
\subsection{N-BEATS Model}
Part of this project, we were tasked with essentially making or finding a "better" model. One of the first ways we tried to make a better model was using the best found standard model (LSTM model for our project) and stacking a bunch of layers hoping that the results would improve. We also tried to change the activation functions along with changing how many units are in each layer. Upon further research it seems that stacking a bunch in a RNN based model seems to be the right approach according to the Neural Basis Expansion Analysis for Time Series (N-BEATS) \cite{nbeats} approach. N-BEATS is a RNN style approach specifically designed for time series classification with a minimum of 256 hidden layers. A Python N-BEATS implementation was used for this project to gather results \cite{nbeats-python}.
\subsection{Data Augmentation}
After some feedback from the presentation, it was brought to our attention that we should be also augmenting the data as the dataset is slightly smaller than desired. The Tsaug \cite{b3} library was used to augment the data in this project. The Tsaug library provides multiple different types of augmenters for time series datasets. One of the augmenters used is a reverse augmenter, basically it reverses the time line of series. Another augmenter used is the add noise augmenter, basically it adds noise to every point of a time series and is independent and identically distributed. The third augmenter used in this project is the drift augmenter. This third augmenter drifts the value of time series from its original values randomly and smoothly.
\subsection{Results}
\subsubsection{Without data Augmentation}
Table \ref{tab:data-wo-aug} contains the results after training the various models on the data provided using two different algorithms to solve the perceived unbalanced data issue. Out of all the models we tried, the LSTM model performed the best with an average accuracy score of about 68\% with Random Over Sampling while using the SMOTEENN method to solve the unbalanced data problem it provided an accuracy of about 80\%. For both methods of dealing with unblanaced data, the LSTM model performed best out of all the models tested. One notable fact is that when using a non augmented dataset, the N-BEATS performed similar to a CNN and MLP based model. The fact that the LSTM model performed best with our data does conincide with our research that RNN based models, such as LSTM, perform best for time series classification \cite{lstm-article}.
\subsubsection{With data Augmentation}
Table \ref{tab:data-w-tsaug-aug} contains the results after training the various models on the data provided using two different algorithms to solve the perceived unbalanced data issue while also using the Tsaug data augmentation. After using the Tsaug data augmentation technique, it seems to have impacted all models and produced worst results when comparing to the previous training performed on non augmented data. In this part, all models produced almost identical results across all metrics, there is no clear winner for which model is better when you augment the data with the Tsaug libraries. When using the Random Over Sampling method to deal with the unbalanced data, the CNN and N-BEATS produced slightly better results. When using the SMOTEENN method to deal with the unbalanced data, the N-BEATS model is the best, and the LSTM model is close to optimal. 
\section{Contribution}
Both group members contributed equally to this project. We leveraged each others strengths to allow for an effective and concentrated group effort. The work for the models were equally distributed.
\begin{thebibliography}{00}
\bibitem{b1} A. Shrestha and . J. Dang, "Deep Learning-Based Real-Time Auto Classification of Smartphone Measured Bridge Vibration Data," 2020. 
\bibitem{b2} D. P. Francis, M. Laustsen and H. Babamoradi, "Classification of colorimetric sensor data using time series," 2021.
\bibitem{b3} M. A. Jethva, “Tsaug: An open-source python package for time series augmentation,” Medium, 22-Nov-2020. [Online]. Available: \url{https://mineshj1291.medium.com/tsaug-an-open-source-python-package-for-time-series-augmentation-85ab9890db16}. [Accessed: 14-Apr-2022]. 
\bibitem{b4} “Smoteenn,” SMOTEENN - Version 0.9.0. [Online]. Available: \url{https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html}. [Accessed: 14-Apr-2022].
\bibitem{b5} N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 321-357, 2002. 
\bibitem{b6} G. Batista, R. C. Prati, M. C. Monard. “A study of the behavior of several methods for balancing machine learning training data,” ACM Sigkdd Explorations Newsletter 6 (1), 20-29, 2004.
\bibitem{github} G. Ankenmann and D. Akhavannasab, ITEC5920 Project GitHub Repository. [Online]. Available: \url{https://github.com/devagent42/ITEC5902-Project}. [Accessed: 15-Apr-2022]. 
\bibitem{keras} Keras, “Keras. Simple. flexible. powerful.,” Keras. [Online]. Available: \url{https://keras.io/}. [Accessed: 15-Apr-2022].
\bibitem{nbeats} B. N. Oreshkin, D. Carpov, N. Chapados, and Y. Bengio, “N-beats: Neural basis expansion analysis for interpretable time series forecasting,” arXiv.org, 20-Feb-2020. [Online]. Available: \url{https://arxiv.org/abs/1905.10437}. [Accessed: 15-Apr-2022]. 
\bibitem{nbeats-python} P. Remy, Philipperemy/N-Beats: Keras/pytorch implementation of N-beats: Neural basis expansion analysis for interpretable time series forecasting. [Online]. Available: \url{https://github.com/philipperemy/n-beats}. [Accessed: 15-Apr-2022]. 
\bibitem{b7} J. Brownlee, “LSTMs for human activity recognition time series classification,” Machine Learning Mastery, 27-Aug-2020. [Online]. Available: \url{https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/}. [Accessed: 15-Apr-2022]. 
\bibitem{lstm-article} M. D. Pra, “Time series forecasting with deep learning and attention mechanism,” Medium, 05-Nov-2020. [Online]. Available: \url{https://towardsdatascience.com/time-series-forecasting-with-deep-learning-and-attention-mechanism-2d001fc871fc}. [Accessed: 15-Apr-2022]. 

\bibitem{b8} Yang, Chao-Lung and Chen, Zhi-Xuan and Yang, Chen-Yi, Sensor classification using convolutional neural network by encoding multivariate time series as two-dimensional colored images, vol. 20. MDPI, 2019, pp.168.

\bibitem{ramakrishnan2018network} Ramakrishnan, Nipun and Soni, Tarun, Network traffic prediction using recurrent neural networks, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), 2018, pp.187-193.

\bibitem{hidasi2015session} Hidasi, Bal{\'a}zs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos, Session-based recommendations with recurrent neural networks, arXiv preprint arXiv:1511.06939, 2015

\bibitem{lang2017understanding} Lang, Tobias and Rettenmeier, Matthias, Understanding consumer behavior with recurrent neural networks, Workshop on Machine Learning Methods for Recommender Systems, 2017
 
\bibitem{toth2017predicting} Toth, Arthur and Tan, Louis and Di Fabbrizio, Giuseppe and Datta, Ankur, Predicting shopping behavior with mixture of RNNs, eCOM@ SIGIR, 2017

\bibitem{croda2019sales} Croda, Rosa Mar{\'\i}a Cant{\'o}n and Romero, Dami{\'a}n Emilio Gibaja and Morales, Santiago-Omar Caballero, Sales prediction through neural networks for a small dataset, Vol. 5, NO. 4, pp. 35-41, UNIR-Universidad Internacional de La Rioja, 2019

\bibitem{elmasdotter2018comparative} Elmasdotter, Ajla and Nystr{\"o}mer, Carl, A comparative study between LSTM and ARIMA for sales forecasting in retail, 2018

\bibitem{shrestha2020deep} Shrestha, Ashish and Dang, Ji, Deep learning-based real-time auto classification of smartphone measured bridge vibration data,Vol. 20, NO. 9, Multidisciplinary Digital Publishing Institute, 2020
\end{thebibliography}

\section{Appendix}
%%% Table 1

\begin{landscape}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{clclllclllclllclllclllclll}
\hline
\multicolumn{26}{|c|}{\textbf{Data Table of the results without data augmentation}} \\ \hline
\multicolumn{26}{|c|}{\textbf{Random Over Sampling}} \\ \hline
\textbf{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.392} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.395} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.450} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.630} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.457} & \multicolumn{1}{l|}{0.543} & \multicolumn{1}{l|}{0.493} & \multicolumn{1}{l|}{0.493} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.364} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.365} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{c|}{0.461} & \multicolumn{1}{l|}{0.522} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.605} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.315} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.457} & \multicolumn{1}{l|}{0.543} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.491} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\cellcolor[HTML]{32CB00}\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.126} & \multicolumn{1}{l|}{0.324} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.183} & \multicolumn{1}{l|}{0.183} & \multicolumn{1}{c|}{0.126} & \multicolumn{1}{l|}{0.324} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.183} & \multicolumn{1}{l|}{0.183} & \multicolumn{1}{c|}{0.439} & \multicolumn{1}{l|}{0.796} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.682} & \multicolumn{1}{l|}{0.682} & \multicolumn{1}{c|}{0.354} & \multicolumn{1}{l|}{0.569} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.424} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{c|}{0.127} & \multicolumn{1}{l|}{0.260} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.179} & \multicolumn{1}{l|}{0.179} & \multicolumn{1}{c|}{0.394} & \multicolumn{1}{l|}{0.851} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.702} & \multicolumn{1}{l|}{0.702} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.355} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.335} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.446} & \multicolumn{1}{l|}{0.527} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.499} & \multicolumn{1}{l|}{0.581} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.273} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.545} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.484} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{l}{} &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  \\ \hline
\multicolumn{26}{|c|}{\textbf{SMOTEENN}} \\ \hline
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.248} & \multicolumn{1}{l|}{0.502} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.248} & \multicolumn{1}{l|}{0.502} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.456} & \multicolumn{1}{l|}{0.539} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.711} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.250} & \multicolumn{1}{l|}{0.400} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.554} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.554} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.460} & \multicolumn{1}{l|}{0.564} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{l|}{0.564} & \multicolumn{1}{l|}{0.529} & \multicolumn{1}{l|}{0.529} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.277} & \multicolumn{1}{l|}{0.277} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.515} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\cellcolor[HTML]{00D2CB}\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.043} & \multicolumn{1}{l|}{0.379} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.133} & \multicolumn{1}{l|}{0.133} & \multicolumn{1}{l|}{0.043} & \multicolumn{1}{l|}{0.379} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.133} & \multicolumn{1}{l|}{0.133} & \multicolumn{1}{l|}{0.470} & \multicolumn{1}{l|}{0.960} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.801} & \multicolumn{1}{l|}{0.801} & \multicolumn{1}{l|}{0.208} & \multicolumn{1}{l|}{0.616} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.349} & \multicolumn{1}{l|}{0.349} & \multicolumn{1}{l|}{0.078} & \multicolumn{1}{l|}{0.541} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.178} & \multicolumn{1}{l|}{0.178} & \multicolumn{1}{l|}{0.485} & \multicolumn{1}{l|}{0.882} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.721} & \multicolumn{1}{l|}{0.721} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.406} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.406} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.430} & \multicolumn{1}{l|}{0.531} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.499} & \multicolumn{1}{l|}{0.639} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.250} & \multicolumn{1}{l|}{0.267} & \multicolumn{1}{l|}{0.252} & \multicolumn{1}{l|}{0.252} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.509} & \multicolumn{1}{l|}{0.509} \\ \cline{1-1} \cline{3-26} 
\end{tabular}%
}
\caption{Data table of the results from the models without data augmentation}
\label{tab:data-wo-aug}
\end{table}
\end{landscape}


%%%
\begin{landscape}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{clclllclllclllclllclllclll}
\hline
\multicolumn{26}{|c|}{\textbf{Data Table of the results with tasug data augmentation}} \\ \hline
\multicolumn{26}{|c|}{\textbf{Random Over Sampling}} \\ \hline
\textbf{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.436} & \multicolumn{1}{l|}{0.514} & \multicolumn{1}{l|}{0.497} & \multicolumn{1}{l|}{0.497} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.549} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.503} & \multicolumn{1}{l|}{0.503} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.476} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.544} & \multicolumn{1}{l|}{0.476} & \multicolumn{1}{l|}{0.476} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.367} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.367} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{c|}{0.442} & \multicolumn{1}{l|}{0.514} & \multicolumn{1}{l|}{0.487} & \multicolumn{1}{l|}{0.487} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.606} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.294} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.544} & \multicolumn{1}{l|}{0.485} & \multicolumn{1}{l|}{0.485} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.316} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.316} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.414} & \multicolumn{1}{l|}{0.525} & \multicolumn{1}{l|}{0.490} & \multicolumn{1}{l|}{0.490} & \multicolumn{1}{c|}{0.499} & \multicolumn{1}{l|}{0.562} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.251} & \multicolumn{1}{l|}{0.251} & \multicolumn{1}{c|}{0.468} & \multicolumn{1}{l|}{0.521} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.490} & \multicolumn{1}{l|}{0.490} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.325} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.325} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.437} & \multicolumn{1}{l|}{0.536} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.491} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.571} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.251} & \multicolumn{1}{l|}{0.251} & \multicolumn{1}{c|}{0.479} & \multicolumn{1}{l|}{0.521} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.490} & \multicolumn{1}{l|}{0.490} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{l}{} &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  \\ \hline
\multicolumn{26}{|c|}{\textbf{SMOTEENN}} \\ \hline
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.517} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.578} & \multicolumn{1}{l|}{0.578} & \multicolumn{1}{l|}{0.492} & \multicolumn{1}{l|}{0.647} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.244} & \multicolumn{1}{l|}{0.416} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.530} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{0.576} & \multicolumn{1}{l|}{0.576} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.348} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.348} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.347} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.572} & \multicolumn{1}{l|}{0.572} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.597} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.244} & \multicolumn{1}{l|}{0.278} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.530} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{0.581} & \multicolumn{1}{l|}{0.581} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.363} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.363} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.362} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.594} & \multicolumn{1}{l|}{0.594} & \multicolumn{1}{l|}{0.489} & \multicolumn{1}{l|}{0.602} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.240} & \multicolumn{1}{l|}{0.301} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.243} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.350} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.590} & \multicolumn{1}{l|}{0.590} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\cellcolor[HTML]{00D2CB}\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.387} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.387} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.397} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.599} & \multicolumn{1}{l|}{0.599} & \multicolumn{1}{l|}{0.488} & \multicolumn{1}{l|}{0.632} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.240} & \multicolumn{1}{l|}{0.339} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.243} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.400} & \multicolumn{1}{l|}{0.500} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.596} & \multicolumn{1}{l|}{0.596} \\ \cline{1-1} \cline{3-26} 
\end{tabular}%
}
\caption{Data table of the results from the models with tsaug data augmentation}
\label{tab:data-w-tsaug-aug}
\end{table}
\end{landscape}

\end{document}
