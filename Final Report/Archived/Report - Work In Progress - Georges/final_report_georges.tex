\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{lscape}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Time Series Classification \\ ITEC5920 Final Project Report}

\author{\IEEEauthorblockN{Georges Ankenmann}
\IEEEauthorblockA{\textit{School of Information Technology} \\
\textit{Carleton University}\\
Ottawa, Canada \\
GeorgesAnkenmann@cmail.carleton.ca}
\and
\IEEEauthorblockN{Davood Akhavannasab}
\IEEEauthorblockA{\textit{School of Information Technology} \\
\textit{Carleton University}\\
Ottawa, Canada \\
DavoodAkhavannasab@cmail.carleton.ca}

}

\maketitle

\begin{abstract}
In this project we are tasked to come up with various deep learning models that are to be trained on a provided dataset. This paper talks about our approach, our chosen models, and the results of training the models on the data.
\end{abstract}

\begin{IEEEkeywords}
deep learning, machine learning, time, series, classification, neural network, cnn, lstm, mlp, vgg, convolutional neural network, multilayer perceptron, long short-term memory, very deep convolutional networks, n-beats
\end{IEEEkeywords}

\section{Introduction}
Nowadays, sensors can be seen in many devices such as smartphones, automobiles, and industrial instruments. Also, sensor information plays a critical role in a wide range of industries from health to safety. This information usually comes in a time-series format can be helpful in different fields such as disaster prevention, human health alerts, and air quality control by measurement interpretation. Some sensor information may contain noise (usually environmentally). We can find patterns by classifying the sensor information. The most common challenging issues of classification application are when we face imbalanced data and lack of training data. For example, if you consider a time series data set containing vibration data of a bridge, we will face a lack of earthquake information while it is a rare phenomenon. In several related works, CNN (Convolutional Neural Network), Multilayer Perceptrons (MLP), and LSTM (Long Short Term Memory network) have succeeded in time-series classification problems.
\section{Research and Literature Review}
\section{Methodology}
We are given a dataset that contains a matrix of 336 measurements with each measurement contains 3000 data samples. With this data, we must train a deep learning model that will allow for automatic classification of new data. Data is already standardised, so we do not need to reduce it further. We will then proceed with training and comparing various models, notably Multilayer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and a hybrid of models. We want to have multiple models to choose from as one model might be able to more accurately classify new sensor data over another given the available dataset. Once we have a trained model, we will want to validate the model by feeding it existing data to confirm the expected results, making adjustments accordingly. Once we have confirmed that the models are trained correctly, we will be feeding it new data and provide results.
\section{Results}
See table \ref{tab:data-wo-aug} for the results of the data without augmentation. See table \ref{tab:data-w-tsaug-aug} for the results of the data with augmentation.
\section{Discussion}
\subsection{Source Code}
All the source code for this project is included in the submission and it is also available on the project's GitHub repository \cite{github}.
\subsection{Data}
The data was provided to us for this project. It consisted of sensor measurements from 336 sensors, with 3000 measurements for each sensor. We initially identified that the data was unbalanced and proceeded to fix this with random over sampling. The Keras Python libraries \cite{keras} were used for most of the project. Tensorflow and other libraries were used to augment the Keras libraries. Early stoppage was implemented for all models with idendical stoppage properties to allow for consistent training. The Root Mean Square Error (RMSE) values were monitored and training was stopped if after 15 epochs there was no significant decrease in the RMSE values. According to our research, a "better" model has a lower RMSE value. Table \ref{tab:data-wo-aug} and table \ref{tab:data-w-tsaug-aug} contains the min, max, average, and mean, of the tracked metrics. This data in this table will be discussed shortly in the next sections. A Graphical Processor Unit (GPU) was used as much as possible to speed up the training of the various models.
\subsection{Data Augmentation and Unbalanced Data}
Upon feedback from the presentation from the Professor and other students, we proceeded to augment the data using an open source Python library called Tsaug \cite{b3} and used the SMOTEENN algorithm \cite{b4} to fix the unbalanced data and the data augmentation issues noted during the presentation. The SMOTEENN algorithm uses a combination of over sampling and under sampling techniques. It uses the Synthetic Minority Over-sampling Technique (SMOTE) \cite{b5} for over sampling, and Edited Nearest Neighbours (ENN) for under sampling \cite{b6}. After using the two techniques to fix the unbalanced data and using the Tsaug library for data augmentation, we proceeded to train the models on the provided dataset.
\subsection{CNN Model}
The first model we designed was a Convolutional Neural Network (CNN) based model. Upon playing around with the parameters and mixing and matching layers, we found that a 12 layer model with 10 hidden layers offered the best results for our dataset. The hidden layers consisted of alternating Keras Conv1D layers and Keras MaxPooling1D layers with decreasing units. The output layer is a single Keras Dense layer with one single unit.
\subsection{MLP Model}
The second model we designed was a Multilayer Perceptron (MLP) based model. Upon playing around with the parameters and mixing and matching layers, we found that a 12 layer model with 10 hidden layers offered decent performance. All of the layers consisted of the Keras Dense layers with a decreasing amount of units ("neurons") for each layer. The output layer is a single Keras Dense layer with one single unit. 
\subsection{LTSM Model}
The third model we designed was a Long short-term memory (LSTM) based network. LSTM is a type of a Recurrent Neural Network (RNN). Similar to the previous models, we found that a 12 layer model with 10 hidden layers offers decent performance. The hidden layers consisted of one Keras LSTM layer with 50 units which then feed into 10 Keras Dense layers with 32 units each. The output layer is a single Keras Dense layer with one single unit.
\subsection{N-BEATS Model}
Part of this project, we were tasked with essentially making or finding a "better" model. One of the first ways we tried to make a better model was using the best found standard model (LSTM model for our project) and stacking a bunch of layers hoping that the results would improve. We also tried to change the activation functions along with changing how many units are in each layer. Upon further research it seems that stacking a bunch in a RNN based model seems to be the right approach according to the Neural Basis Expansion Analysis for Time Series (N-BEATS) \cite{nbeats} approach. N-BEATS is a RNN style approach specifically designed for time series classification with a minimum of 256 hidden layers. A Python N-BEATS implementation was used for this project to gather results \cite{nbeats-python}.
\subsection{Data Augmentation}
After some feedback from the presentation, it was brought to our attention that we should be also augmenting the data as the dataset is slightly smaller than desired. The Tsaug \cite{b3} library was used to augment the data in this project. The Tsaug library provides multiple different types of augmenters for time series datasets. One of the augmenters used is a reverse augmenter, basically it reverses the time line of series. Another augmenter used is the add noise augmenter, basically it adds noise to every point of a time series and is independent and identically distributed. The third augmenter used in this project is the drift augmenter. This third augmenter drifts the value of time series from its original values randomly and smoothly.
\subsection{Results}
\subsubsection{Without data Augmentation}
Table \ref{tab:data-wo-aug} contains the results after training the various models on the data provided using two different algorithms to solve the perceived unbalanced data issue. Out of all the models we tried, the LSTM model performed the best with an average accuracy score of about 68\% with Random Over Sampling while using the SMOTEENN method to solve the unbalanced data problem it provided an accuracy of about 80\%. For both methods of dealing with unblanaced data, the LSTM model performed best out of all the models tested. One notable fact is that when using a non augmented dataset, the N-BEATS performed similar to a CNN and MLP based model. The fact that the LSTM model performed best with our data does conincide with our research that RNN based models, such as LSTM, perform best for time series classification \cite{lstm-article}.
\subsubsection{With data Augmentation}
Table \ref{tab:data-w-tsaug-aug} contains the results after training the various models on the data provided using two different algorithms to solve the perceived unbalanced data issue while also using the Tsaug data augmentation. After using the Tsaug data augmentation technique, it seems to have impacted all models and produced worst results when comparing to the previous training performed on non augmented data. In this part, all models produced almost identical results across all metrics, there is no clear winner for which model is better when you augment the data with the Tsaug libraries. When using the Random Over Sampling method to deal with the unbalanced data, the CNN and N-BEATS produced slightly better results. When using the SMOTEENN method to deal with the unbalanced data, the N-BEATS model is the best, and the LSTM model is close to optimal. 
\section{Contribution}
Both group members contributed equally to this project. We leveraged each others strengths to allow for an effective and concentrated group effort.
\begin{thebibliography}{00}
\bibitem{b1} A. Shrestha and . J. Dang, "Deep Learning-Based Real-Time Auto Classification of Smartphone Measured Bridge Vibration Data," 2020. 
\bibitem{b2} D. P. Francis, M. Laustsen and H. Babamoradi, "Classification of colorimetric sensor data using time series," 2021.
\bibitem{b3} M. A. Jethva, “Tsaug: An open-source python package for time series augmentation,” Medium, 22-Nov-2020. [Online]. Available: \url{https://mineshj1291.medium.com/tsaug-an-open-source-python-package-for-time-series-augmentation-85ab9890db16}. [Accessed: 14-Apr-2022]. 
\bibitem{b4} “Smoteenn,” SMOTEENN - Version 0.9.0. [Online]. Available: \url{https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html}. [Accessed: 14-Apr-2022].
\bibitem{b5} N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 321-357, 2002. 
\bibitem{b6} G. Batista, R. C. Prati, M. C. Monard. “A study of the behavior of several methods for balancing machine learning training data,” ACM Sigkdd Explorations Newsletter 6 (1), 20-29, 2004.
\bibitem{github} G. Ankenmann and D. Akhavannasab, ITEC5920 Project GitHub Repository. [Online]. Available: \url{https://github.com/devagent42/ITEC5902-Project}. [Accessed: 15-Apr-2022]. 
\bibitem{keras} Keras, “Keras. Simple. flexible. powerful.,” Keras. [Online]. Available: \url{https://keras.io/}. [Accessed: 15-Apr-2022].
\bibitem{nbeats} B. N. Oreshkin, D. Carpov, N. Chapados, and Y. Bengio, “N-beats: Neural basis expansion analysis for interpretable time series forecasting,” arXiv.org, 20-Feb-2020. [Online]. Available: \url{https://arxiv.org/abs/1905.10437}. [Accessed: 15-Apr-2022]. 
\bibitem{nbeats-python} P. Remy, Philipperemy/N-Beats: Keras/pytorch implementation of N-beats: Neural basis expansion analysis for interpretable time series forecasting. [Online]. Available: \url{https://github.com/philipperemy/n-beats}. [Accessed: 15-Apr-2022]. 
\bibitem{b7} J. Brownlee, “LSTMs for human activity recognition time series classification,” Machine Learning Mastery, 27-Aug-2020. [Online]. Available: \url{https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/}. [Accessed: 15-Apr-2022]. 
\bibitem{lstm-article} M. D. Pra, “Time series forecasting with deep learning and attention mechanism,” Medium, 05-Nov-2020. [Online]. Available: \url{https://towardsdatascience.com/time-series-forecasting-with-deep-learning-and-attention-mechanism-2d001fc871fc}. [Accessed: 15-Apr-2022]. 
\end{thebibliography}

\section{Appendix}
%%% Table 1

\begin{landscape}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{clclllclllclllclllclllclll}
\hline
\multicolumn{26}{|c|}{\textbf{Data Table of the results without data augmentation}} \\ \hline
\multicolumn{26}{|c|}{\textbf{Random Over Sampling}} \\ \hline
\textbf{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.392} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.395} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.450} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.630} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.457} & \multicolumn{1}{l|}{0.543} & \multicolumn{1}{l|}{0.493} & \multicolumn{1}{l|}{0.493} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.364} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.365} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{c|}{0.461} & \multicolumn{1}{l|}{0.522} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.605} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.315} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.457} & \multicolumn{1}{l|}{0.543} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.491} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\cellcolor[HTML]{32CB00}\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.126} & \multicolumn{1}{l|}{0.324} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.183} & \multicolumn{1}{l|}{0.183} & \multicolumn{1}{c|}{0.126} & \multicolumn{1}{l|}{0.324} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.183} & \multicolumn{1}{l|}{0.183} & \multicolumn{1}{c|}{0.439} & \multicolumn{1}{l|}{0.796} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.682} & \multicolumn{1}{l|}{0.682} & \multicolumn{1}{c|}{0.354} & \multicolumn{1}{l|}{0.569} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.424} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{c|}{0.127} & \multicolumn{1}{l|}{0.260} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.179} & \multicolumn{1}{l|}{0.179} & \multicolumn{1}{c|}{0.394} & \multicolumn{1}{l|}{0.851} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.702} & \multicolumn{1}{l|}{0.702} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.355} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.335} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.446} & \multicolumn{1}{l|}{0.527} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{c|}{0.499} & \multicolumn{1}{l|}{0.581} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.273} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.545} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.484} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{l}{} &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  \\ \hline
\multicolumn{26}{|c|}{\textbf{SMOTEENN}} \\ \hline
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.248} & \multicolumn{1}{l|}{0.502} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.248} & \multicolumn{1}{l|}{0.502} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.456} & \multicolumn{1}{l|}{0.539} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.711} & \multicolumn{1}{l|}{0.506} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.250} & \multicolumn{1}{l|}{0.400} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.498} & \multicolumn{1}{l|}{0.498} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.554} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{0.554} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.282} & \multicolumn{1}{l|}{0.460} & \multicolumn{1}{l|}{0.564} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{l|}{0.564} & \multicolumn{1}{l|}{0.529} & \multicolumn{1}{l|}{0.529} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.277} & \multicolumn{1}{l|}{0.277} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.515} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.495} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\cellcolor[HTML]{00D2CB}\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.043} & \multicolumn{1}{l|}{0.379} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.133} & \multicolumn{1}{l|}{0.133} & \multicolumn{1}{l|}{0.043} & \multicolumn{1}{l|}{0.379} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.133} & \multicolumn{1}{l|}{0.133} & \multicolumn{1}{l|}{0.470} & \multicolumn{1}{l|}{0.960} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.801} & \multicolumn{1}{l|}{0.801} & \multicolumn{1}{l|}{0.208} & \multicolumn{1}{l|}{0.616} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.349} & \multicolumn{1}{l|}{0.349} & \multicolumn{1}{l|}{0.078} & \multicolumn{1}{l|}{0.541} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.178} & \multicolumn{1}{l|}{0.178} & \multicolumn{1}{l|}{0.485} & \multicolumn{1}{l|}{0.882} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.721} & \multicolumn{1}{l|}{0.721} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.406} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.406} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{0.430} & \multicolumn{1}{l|}{0.531} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.499} & \multicolumn{1}{l|}{0.639} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.505} & \multicolumn{1}{l|}{0.250} & \multicolumn{1}{l|}{0.267} & \multicolumn{1}{l|}{0.252} & \multicolumn{1}{l|}{0.252} & \multicolumn{1}{l|}{0.484} & \multicolumn{1}{l|}{0.516} & \multicolumn{1}{l|}{0.509} & \multicolumn{1}{l|}{0.509} \\ \cline{1-1} \cline{3-26} 
\end{tabular}%
}
\caption{Data table of the results from the models without data augmentation}
\label{tab:data-wo-aug}
\end{table}
\end{landscape}


%%%
\begin{landscape}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{clclllclllclllclllclllclll}
\hline
\multicolumn{26}{|c|}{\textbf{Data Table of the results with tasug data augmentation}} \\ \hline
\multicolumn{26}{|c|}{\textbf{Random Over Sampling}} \\ \hline
\textbf{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{c|}{\textbf{Min}} & \multicolumn{1}{c|}{\textbf{Max}} & \multicolumn{1}{c|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.300} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{c|}{0.436} & \multicolumn{1}{l|}{0.514} & \multicolumn{1}{l|}{0.497} & \multicolumn{1}{l|}{0.497} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.549} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.503} & \multicolumn{1}{l|}{0.503} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.476} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.544} & \multicolumn{1}{l|}{0.476} & \multicolumn{1}{l|}{0.476} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.367} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.367} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{l|}{0.258} & \multicolumn{1}{c|}{0.442} & \multicolumn{1}{l|}{0.514} & \multicolumn{1}{l|}{0.487} & \multicolumn{1}{l|}{0.487} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.606} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{l|}{0.508} & \multicolumn{1}{c|}{0.248} & \multicolumn{1}{l|}{0.294} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{c|}{0.456} & \multicolumn{1}{l|}{0.544} & \multicolumn{1}{l|}{0.485} & \multicolumn{1}{l|}{0.485} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.316} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{l|}{0.316} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.414} & \multicolumn{1}{l|}{0.525} & \multicolumn{1}{l|}{0.490} & \multicolumn{1}{l|}{0.490} & \multicolumn{1}{c|}{0.499} & \multicolumn{1}{l|}{0.562} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.256} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.251} & \multicolumn{1}{l|}{0.251} & \multicolumn{1}{c|}{0.468} & \multicolumn{1}{l|}{0.521} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.490} & \multicolumn{1}{l|}{0.490} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|c|}{\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.325} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.325} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{l|}{0.254} & \multicolumn{1}{c|}{0.437} & \multicolumn{1}{l|}{0.536} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.491} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{c|}{0.500} & \multicolumn{1}{l|}{0.571} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{c|}{0.250} & \multicolumn{1}{l|}{0.257} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.251} & \multicolumn{1}{l|}{0.251} & \multicolumn{1}{c|}{0.479} & \multicolumn{1}{l|}{0.521} & \multicolumn{1}{l|}{\cellcolor[HTML]{32CB00}0.490} & \multicolumn{1}{l|}{0.490} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{l}{} &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  & \multicolumn{1}{l}{} &  &  &  \\ \hline
\multicolumn{26}{|c|}{\textbf{SMOTEENN}} \\ \hline
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{\textbf{Loss}} & \multicolumn{4}{c|}{\textbf{MSE}} & \multicolumn{4}{c|}{\textbf{Accuracy}} & \multicolumn{4}{c|}{\textbf{RMSE}} & \multicolumn{4}{c|}{\textbf{Validation Loss}} & \multicolumn{4}{c|}{\textbf{Validation Accuracy}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{Model}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} & \multicolumn{1}{l|}{\textbf{Min}} & \multicolumn{1}{l|}{\textbf{Max}} & \multicolumn{1}{l|}{\textbf{Avg}} & \multicolumn{1}{l|}{\textbf{Mean}} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{CNN}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.424} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.517} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.578} & \multicolumn{1}{l|}{0.578} & \multicolumn{1}{l|}{0.492} & \multicolumn{1}{l|}{0.647} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.244} & \multicolumn{1}{l|}{0.416} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.253} & \multicolumn{1}{l|}{0.530} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{0.576} & \multicolumn{1}{l|}{0.576} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{MLP}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.348} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.348} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.255} & \multicolumn{1}{l|}{0.347} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.572} & \multicolumn{1}{l|}{0.572} & \multicolumn{1}{l|}{0.491} & \multicolumn{1}{l|}{0.597} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.504} & \multicolumn{1}{l|}{0.244} & \multicolumn{1}{l|}{0.278} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.249} & \multicolumn{1}{l|}{0.530} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{0.581} & \multicolumn{1}{l|}{0.581} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\textbf{LSTM}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.363} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.363} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.362} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{0.594} & \multicolumn{1}{l|}{0.594} & \multicolumn{1}{l|}{0.489} & \multicolumn{1}{l|}{0.602} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.240} & \multicolumn{1}{l|}{0.301} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.243} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.350} & \multicolumn{1}{l|}{0.600} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.590} & \multicolumn{1}{l|}{0.590} \\ \cline{1-1} \cline{3-26} 
\multicolumn{1}{|l|}{\cellcolor[HTML]{00D2CB}\textbf{N-BEATS}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.387} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.239} & \multicolumn{1}{l|}{0.387} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.245} & \multicolumn{1}{l|}{0.245} & \multicolumn{1}{l|}{0.397} & \multicolumn{1}{l|}{0.603} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.599} & \multicolumn{1}{l|}{0.599} & \multicolumn{1}{l|}{0.488} & \multicolumn{1}{l|}{0.632} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.495} & \multicolumn{1}{l|}{0.495} & \multicolumn{1}{l|}{0.240} & \multicolumn{1}{l|}{0.339} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.243} & \multicolumn{1}{l|}{0.243} & \multicolumn{1}{l|}{0.400} & \multicolumn{1}{l|}{0.500} & \multicolumn{1}{l|}{\cellcolor[HTML]{00D2CB}0.596} & \multicolumn{1}{l|}{0.596} \\ \cline{1-1} \cline{3-26} 
\end{tabular}%
}
\caption{Data table of the results from the models with tsaug data augmentation}
\label{tab:data-w-tsaug-aug}
\end{table}
\end{landscape}

\end{document}
